{ 
	"cells": [
		{
			"cell_type": "markdown",
			"metadata": {
				"editable": true,
				"trusted": true
			},
			"source": [
				"Escrever o código necessário para alterar a caixa dos valores da coluna nome para MAIÚSCULO.\n",
				"Imprimir a contagem de linhas presentes no dataframe\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 2,
			"metadata": {
				"editable": true,
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"root\n",
						" |-- nome: string (nullable = true)\n",
						" |-- sexo: string (nullable = true)\n",
						" |-- total: integer (nullable = true)\n",
						" |-- ano: integer (nullable = true)\n",
						"\n",
						"Contagem de linhas no DataFrame: 1825433\n"
					]
				}
			],
			"source": [
				"from pyspark.context import SparkContext\n",
				"from pyspark.sql import SparkSession\n",
				"from pyspark.sql.functions import upper\n",
				"\n",
				"spark = SparkSession.builder.appName(\"MyGlueApp\").getOrCreate()\n",
				"S3_INPUT_PATH = \"s3://aws-glue-assets-477879694723-us-east-1/nomes.csv\"\n",
				"df = spark.read.csv(S3_INPUT_PATH, header=True, inferSchema=True)\n",
				"df = df.withColumn(\"nome\", upper(df[\"nome\"]))\n",
				"\n",
				"# Imprime o schema do DataFrame\n",
				"df.printSchema()\n",
				"\n",
				"# Imprime a contagem de linhas\n",
				"row_count = df.count()\n",
				"print(\"Contagem de linhas no DataFrame:\", row_count)\n"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {
				"editable": true,
				"trusted": true
			},
			"source": [
				"Imprimir a contagem de nomes, agrupando os dados do dataframe pelas colunas ano e sexo.\n",
				"Ordene os dados de modo que o ano mais recente apareça como primeiro registro do dataframe.\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"editable": true,
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": [
				"from pyspark.context import SparkContext\n",
				"from pyspark.sql import SparkSession\n",
				"from pyspark.sql.functions import desc, upper, sum\n",
				"\n",
				"# Inicialize o SparkSession\n",
				"spark = SparkSession.builder.appName(\"MyGlueApp\").getOrCreate()\n",
				"S3_INPUT_PATH = \"s3://aws-glue-assets-477879694723-us-east-1/nomes.csv\"\n",
				"df = spark.read.csv(S3_INPUT_PATH, header=True, inferSchema=True)\n",
				"\n",
				"# Altera a caixa dos valores da coluna \"nome\" para maiúsculo\n",
				"df = df.withColumn(\"nome\", upper(df[\"nome\"]))\n",
				"\n",
				"# Agrupa os dados pelas colunas \"ano\" e \"sexo\" e soma a coluna \"total\"\n",
				"grouped_df = df.groupBy(\"ano\", \"sexo\").agg(sum(\"total\").alias(\"total_soma\"))\n",
				"\n",
				"# Ordena os dados pelo ano de forma descendente (do mais recente para o mais antigo)\n",
				"grouped_df = grouped_df.orderBy(desc(\"ano\"))\n",
				"\n",
				"grouped_df.show()\n",
				"\n",
				"+----+----+----------+\n",
				"| ano|sexo|total_soma|\n",
				"+----+----+----------+\n",
				"|2014|   F|   1768775|\n",
				"|2014|   M|   1901376|\n",
				"|2013|   F|   1745339|\n",
				"|2013|   M|   1881463|\n",
				"|2012|   M|   1889414|\n",
				"|2012|   F|   1753922|\n",
				"|2011|   F|   1753500|\n",
				"|2011|   M|   1893230|\n",
				"|2010|   M|   1913851|\n",
				"|2010|   F|   1772738|\n",
				"|2009|   F|   1832925|\n",
				"|2009|   M|   1979303|\n",
				"|2008|   F|   1887234|\n",
				"|2008|   M|   2036289|\n",
				"|2007|   F|   1919408|\n",
				"|2007|   M|   2072139|\n",
				"|2006|   F|   1898463|\n",
				"|2006|   M|   2052377|\n",
				"|2005|   M|   1994841|\n",
				"|2005|   F|   1845379|\n",
				"+----+----+----------+\n",
				"only showing top 20 rows"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {
				"editable": true,
				"trusted": true
			},
			"source": [
				"Apresentar qual foi o nome feminino e masculino com mais registros e em que ano ocorreu.\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"editable": true,
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": [
				"from pyspark.sql.functions import desc\n",
				"\n",
				"# Filtra os registros do sexo feminino\n",
				"df_feminino = df.filter(df[\"sexo\"] == \"F\")\n",
				"# Encontre o nome feminino com mais registros\n",
				"nome_fem_com_mais_registros = df_feminino.groupBy(\"nome\").agg({\"total\": \"max\"}).sort(desc(\"max(total)\")).first()\n",
				"# Encontra o ano em que o nome feminino mais registrado ocorreu\n",
				"ano_nome_fem_mais_registrado = df_feminino.filter(df_feminino[\"nome\"] == nome_fem_com_mais_registros[\"nome\"]).groupBy(\"ano\").agg({\"total\": \"max\"}).sort(desc(\"max(total)\")).first()[\"ano\"]\n",
				"# Imprima o resultado\n",
				"print(f\"O nome feminino com mais registros é '{nome_fem_com_mais_registros['nome']}' com um total de {nome_fem_com_mais_registros['max(total)']} registros e ocorreu no ano {ano_nome_fem_mais_registrado}.\")\n",
				"\n",
				"# Filtra os registros do sexo masculino\n",
				"df_masculino = df.filter(df[\"sexo\"] == \"M\")\n",
				"# Encontra o nome masculino com mais registros\n",
				"nome_masc_com_mais_registros = df_masculino.groupBy(\"nome\").agg({\"total\": \"max\"}).sort(desc(\"max(total)\")).first()\n",
				"# Encontra o ano em que o nome masculino mais registrado ocorreu\n",
				"ano_nome_masc_mais_registrado = df_masculino.filter(df_masculino[\"nome\"] == nome_masc_com_mais_registros[\"nome\"]).groupBy(\"ano\").agg({\"total\": \"max\"}).sort(desc(\"max(total)\")).first()[\"ano\"]\n",
				"# Imprima o resultado\n",
				"print(f\"O nome masculino com mais registros é '{nome_masc_com_mais_registros['nome']}' com um total de {nome_masc_com_mais_registros['max(total)']} registros e ocorreu no ano {ano_nome_masc_mais_registrado}.\")\n",
				"\n",
				"\n",
				"\n",
				"O nome feminino com mais registros é 'LINDA' com um total de 99680 registros e ocorreu no ano 1947.\n",
				"O nome masculino com mais registros é 'JAMES' com um total de 94755 registros e ocorreu no ano 1947."
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {
				"editable": true,
				"trusted": true
			},
			"source": [
				"Apresentar o total de registros (masculinos e femininos) para cada ano presente no dataframe.\n",
				"Considere apenas as primeiras 10 linhas, ordenadas pelo ano, de forma crescente.\n",
				"\n"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"editable": true,
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": [
				"# Importe as bibliotecas necessárias\n",
				"from pyspark.sql import SparkSession\n",
				"from pyspark.sql.functions import upper, sum\n",
				"\n",
				"# Inicialize o SparkSession\n",
				"spark = SparkSession.builder.appName(\"MyGlueApp\").getOrCreate()\n",
				"\n",
				"# Defina o caminho de entrada para o arquivo CSV\n",
				"S3_INPUT_PATH = \"s3://aws-glue-assets-477879694723-us-east-1/nomes.csv\"\n",
				"\n",
				"# Leia o arquivo CSV do S3\n",
				"df = spark.read.csv(S3_INPUT_PATH, header=True, inferSchema=True)\n",
				"\n",
				"# Altera a caixa dos valores da coluna \"nome\" para maiúsculo\n",
				"df = df.withColumn(\"nome\", upper(df[\"nome\"]))\n",
				"\n",
				"# Filtra os registros do sexo feminino\n",
				"df_feminino = df.filter(df[\"sexo\"] == \"F\")\n",
				"\n",
				"# Agrupe os dados pelo ano e some a coluna \"total\"\n",
				"total_registros_por_ano = df_feminino.groupBy(\"ano\").agg(sum(\"total\").alias(\"total_registros\"))\n",
				"\n",
				"# Ordene os resultados pelo ano, de forma crescente (não use desc)\n",
				"total_registros_por_ano = total_registros_por_ano.sort(\"ano\")\n",
				"\n",
				"# Limite os resultados às primeiras 10 linhas\n",
				"total_registros_por_ano = total_registros_por_ano.limit(10)\n",
				"\n",
				"# Imprima os resultados\n",
				"for registro in total_registros_por_ano.collect():\n",
				"    print(f\"{registro['ano']}: {registro['total_registros']}\")\n",
				"\n",
				"\n",
				"1880: 90993\n",
				"1881: 91954\n",
				"1882: 107850\n",
				"1883: 112321\n",
				"1884: 129022\n",
				"1885: 133055\n",
				"1886: 144535\n",
				"1887: 145982\n",
				"1888: 178627\n",
				"1889: 178366"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [],
			"source": [
				"Escrever o conteúdo do dataframe com os valores de nome em maiúsculo no S3.\n",
				"A gravação deve ocorrer no subdiretório frequencia_registro_nomes_eua do path s3://<BUCKET>/lab-glue/\n",
				"O formato deve ser JSON\n",
				"O particionamento deverá ser realizado pelas colunas sexo e ano (nesta ordem)"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 8,
			"metadata": {
				"tags": [],
				"trusted": true,
				"vscode": {
					"languageId": "python_glue_session"
				}
			},
			"outputs": [
				{
					"name": "stdout",
					"output_type": "stream",
					"text": [
						"\n"
					]
				}
			],
			"source": [
				"from pyspark.context import SparkContext\n",
				"from pyspark.sql import SparkSession\n",
				"from pyspark.sql.functions import upper\n",
				"\n",
				"# Inicialize o SparkSession\n",
				"spark = SparkSession.builder.appName(\"MyGlueApp\").getOrCreate()\n",
				"\n",
				"# Defina o caminho de entrada para o arquivo nomes.csv no S3\n",
				"S3_INPUT_PATH = \"s3://aws-glue-assets-477879694723-us-east-1/nomes.csv\"\n",
				"\n",
				"# Leia o arquivo CSV do S3\n",
				"df = spark.read.csv(S3_INPUT_PATH, header=True, inferSchema=True)\n",
				"\n",
				"# Altera a caixa dos valores da coluna \"nome\" para maiúsculo\n",
				"df = df.withColumn(\"nome\", upper(df[\"nome\"]))\n",
				"\n",
				"# Defina o caminho de saída no S3 com o particionamento adequado\n",
				"S3_OUTPUT_PATH = \"s3://aws-glue-assets-477879694723-us-east-1/frequencia_registro_nomes_eua/\"\n",
				"\n",
				"# Grave o DataFrame no S3 em formato JSON e com particionamento por sexo e ano\n",
				"df.write.partitionBy(\"sexo\", \"ano\").json(S3_OUTPUT_PATH)\n"
			]
		}
	],
	"metadata": {
		"kernelspec": {
			"display_name": "Glue PySpark",
			"language": "python",
			"name": "glue_pyspark"
		},
		"language_info": {
			"codemirror_mode": {
				"name": "python",
				"version": 3
			},
			"file_extension": ".py",
			"mimetype": "text/x-python",
			"name": "Python_Glue_Session",
			"pygments_lexer": "python3"
		}
	},
	"nbformat": 4,
	"nbformat_minor": 4
}
